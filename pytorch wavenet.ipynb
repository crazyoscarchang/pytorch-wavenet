{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from utils import bin_and_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetDataSet(Dataset):\n",
    "    def __init__(self, audio_dir, num_frames_input, num_frames_output):\n",
    "        \"\"\"\n",
    "        Assume we have a directory audio_dir, containing wav files as our dataset\n",
    "        \"\"\"\n",
    "        self.data = glob.glob(audio_dir + \"/*.wav\")\n",
    "        self.num_frames_input = num_frames_input\n",
    "        self.num_frames_output = num_frames_output\n",
    "        self.len_subset = num_frames_input + num_frames_output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.data[idx]\n",
    "        # read a wavfile\n",
    "        frequency, data = wavfile.read(fname)\n",
    "        # select a random starting point within that file (leaving room to subset into x/y)\n",
    "        random_start = np.random.randint(0, len(data) - self.len_subset)\n",
    "        # select a subsete of that wavfile\n",
    "        subset = data[random_start:random_start + self.len_subset]\n",
    "        # x is the first set of frames in the subset\n",
    "        x = subset[: self.num_frames_input]\n",
    "        # we are going to try and predict everything after the split\n",
    "        y = subset[self.num_frames_input: ]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = WaveNetDataSet(\"./data\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "   11\n",
       "   65\n",
       "  126\n",
       "  150\n",
       "  111\n",
       "  123\n",
       "  164\n",
       "  184\n",
       "  179\n",
       "  171\n",
       "  161\n",
       "  196\n",
       "  199\n",
       "  222\n",
       "  255\n",
       "  274\n",
       "  280\n",
       "  312\n",
       "  380\n",
       "  450\n",
       "  481\n",
       "  458\n",
       "  442\n",
       "  436\n",
       "  436\n",
       "  405\n",
       "  373\n",
       "  378\n",
       "  375\n",
       "  392\n",
       "  428\n",
       "  408\n",
       "  421\n",
       "  448\n",
       "  448\n",
       "  507\n",
       "  565\n",
       "  541\n",
       "  511\n",
       "  483\n",
       "  482\n",
       "  455\n",
       "  425\n",
       "  347\n",
       "  342\n",
       "  391\n",
       "  411\n",
       "  378\n",
       "  370\n",
       "  414\n",
       "  470\n",
       "  460\n",
       "  398\n",
       "  400\n",
       "  422\n",
       "  417\n",
       "  349\n",
       "  282\n",
       "  299\n",
       "  320\n",
       "  304\n",
       "  243\n",
       "  278\n",
       "  289\n",
       "  301\n",
       "  270\n",
       "  272\n",
       "  239\n",
       "  231\n",
       "  194\n",
       "  164\n",
       "  158\n",
       "  117\n",
       "   13\n",
       "   -4\n",
       "   82\n",
       "  124\n",
       "   62\n",
       "    1\n",
       "   33\n",
       "   99\n",
       "   94\n",
       "   25\n",
       "   36\n",
       "  110\n",
       "  137\n",
       "   48\n",
       "  -15\n",
       "  -49\n",
       "  -65\n",
       " -128\n",
       " -129\n",
       " -100\n",
       " -130\n",
       " -140\n",
       " -119\n",
       "  -33\n",
       "   17\n",
       "   79\n",
       "   32\n",
       " [torch.ShortTensor of size 100], \n",
       "   28\n",
       "   56\n",
       "   80\n",
       "  119\n",
       "  107\n",
       "   86\n",
       "   56\n",
       "   35\n",
       "   44\n",
       "  109\n",
       " [torch.ShortTensor of size 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
